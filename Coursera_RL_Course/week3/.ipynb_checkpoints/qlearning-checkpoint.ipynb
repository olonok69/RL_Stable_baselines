{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning\n",
    "\n",
    "This notebook will guide you through implementation of vanilla Q-learning algorithm.\n",
    "\n",
    "You need to implement QLearningAgent (follow instructions for each method) and use it on a number of tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'\n",
    "        \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting qlearning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile qlearning.py\n",
    "from collections import defaultdict\n",
    "import random, math\n",
    "import numpy as np\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
    "        \"\"\"\n",
    "        Q-Learning Agent\n",
    "        based on http://inst.eecs.berkeley.edu/~cs188/sp09/pacman.html\n",
    "        Instance variables you have access to\n",
    "          - self.epsilon (exploration prob)\n",
    "          - self.alpha (learning rate)\n",
    "          - self.discount (discount rate aka gamma)\n",
    "\n",
    "        Functions you should use\n",
    "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
    "            which returns legal actions for a state\n",
    "          - self.get_qvalue(state,action)\n",
    "            which returns Q(state,action)\n",
    "          - self.set_qvalue(state,action,value)\n",
    "            which sets Q(state,action) := value\n",
    "\n",
    "        !!!Important!!!\n",
    "        Note: please avoid using self._qValues directly. \n",
    "            There's a special self.get_qvalue/set_qvalue for that.\n",
    "        \"\"\"\n",
    "\n",
    "        self.get_legal_actions = get_legal_actions\n",
    "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.discount = discount\n",
    "\n",
    "    def get_qvalue(self, state, action):\n",
    "        \"\"\" Returns Q(state,action) \"\"\"\n",
    "        return self._qvalues[state][action]\n",
    "\n",
    "    def set_qvalue(self,state,action,value):\n",
    "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
    "        self._qvalues[state][action] = value\n",
    "\n",
    "    #---------------------START OF YOUR CODE---------------------#\n",
    "\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        Compute your agent's estimate of V(s) using current q-values\n",
    "        V(s) = max_over_action Q(state,action) over possible actions.\n",
    "        Note: please take into account that q-values can be negative.\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return 0.0\n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        value = max([self.get_qvalue(state,action) for action in possible_actions])\n",
    "\n",
    "        return value\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        You should do your Q-Value update here:\n",
    "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
    "        \"\"\"\n",
    "\n",
    "        #agent parameters\n",
    "        gamma = self.discount\n",
    "        learning_rate = self.alpha\n",
    "\n",
    "        qvalue_next = reward+gamma*self.get_value(next_state)\n",
    "        qvalue = (learning_rate*qvalue_next) + (1-learning_rate)*self.get_qvalue(state,action)\n",
    " \n",
    "        \n",
    "        self.set_qvalue(state, action, qvalue)\n",
    "\n",
    "    \n",
    "    def get_best_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the best action to take in a state (using current q-values). \n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        action_value_dict = {action: self.get_qvalue(state, action) for action in possible_actions}\n",
    "        best_action = sorted(action_value_dict, key=lambda x:action_value_dict[x], reverse=True)[0]\n",
    "\n",
    "        return best_action\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the action to take in the current state, including exploration.  \n",
    "        With probability self.epsilon, we should take a random action.\n",
    "            otherwise - the best policy action (self.getPolicy).\n",
    "        \n",
    "        Note: To pick randomly from a list, use random.choice(list). \n",
    "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
    "              and compare it with your probability\n",
    "        \"\"\"\n",
    "\n",
    "        # Pick Action\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        action = None\n",
    "\n",
    "        #If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        #agent parameters:\n",
    "        epsilon = self.epsilon\n",
    "\n",
    "        explora = random.random()\n",
    "        if explora < epsilon:\n",
    "            chosen_action = np.random.choice(possible_actions)\n",
    "        else:\n",
    "            chosen_action = self.get_best_action(state)\n",
    "        \n",
    "        return chosen_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it on taxi\n",
    "\n",
    "Here we use the qlearning agent on taxi env from openai gym.\n",
    "You will need to insert a few agent functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"FrozenLake-v0\")\n",
    "\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_legal_actions = lambda s: range(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlearning import QLearningAgent\n",
    "\n",
    "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
    "                       get_legal_actions = lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_train(env,agent,t_max=10**4):\n",
    "    \"\"\"\n",
    "    This function should \n",
    "    - run a full game, actions given by agent's e-greedy policy\n",
    "    - train agent using agent.update(...) whenever it is possible\n",
    "    - return total reward\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        # get agent to pick action given state s.\n",
    "        a = agent.get_action(s)\n",
    "        \n",
    "        next_s, r, done, _ = env.step(a)\n",
    "        \n",
    "        # train (update) agent for state s\n",
    "        agent.update(s, a, r, next_s)\n",
    "        \n",
    "        s = next_s\n",
    "        total_reward +=r\n",
    "        if done: break\n",
    "        \n",
    "    return total_reward\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 2.9191091959171894e-05 mean reward = 9.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZxbZb348c83mX2mM51pO+10ug6d7rS0HdqyCBQKLYsWVK4FFVyr3qKigpeCV0FEueoVFHGpWn7iVQEVpEK1UECRtQtL6ULbgbZ0upeW6T7r8/sjJ5mT5JwkM0kmMznf9+s1rybPOTl5cpp88+T7LEeMMSillPIWX6YroJRSqvtp8FdKKQ/S4K+UUh6kwV8ppTxIg79SSnlQTqYrkIj+/fubESNGZLoaSinVq6xZs+aAMWaA07ZeEfxHjBjB6tWrM10NpZTqVURku9s2TfsopZQHafBXSikP0uCvlFIepMFfKaU8SIO/Ukp5kAZ/pZTyIA3+SinlQRr8Vbc42dLGn1bvIF1LiBtj2PneibQcuzvsP9LExt2H+feW/Z1+bFu7Yd/hk11+7j2NXX9sT9Ta1s7eLpyP3Y094/2zu/EE7e3pX2rff+utt6b9SZK1ePHiWxcsWJDpaqTFjX96nVfeeY+za/t36nEHjzWz78hJ+hblAdB4ooXdjScpL8rjL2saONHSxuC+hWGP2XHwOA+ueofGEy1c+KNnOdHSxo6Dx7nxT69z3pgBlBbmhvY91tTKvc/UM214OW3thjXbDzG4bwFNre385KktTKwuI8fn456n6hk7qA/txvCBnz7Pfc9vZcXGvTxf/y7nj63EGMPrDe+x5PmtfH/5JqYNL6dvUR73PL2FqcPKyfX7WLezkRUb9/HLZ9/idy8G5qR8d9lGrphSjYjwt9d3sWLjXk4fUY6IsOPgcTbsOszWA8e47g+vMq6qD9fet5IfLN/EyZbAB3/84NLAeTnewvL1e/jtC9vZsOswFcV5/PCJzbz2znvsP9rEc1sOsGLjXvYePsnNj7zB5adVk+MPtIlOtrSxdmcjew83MaisAIAjJ1v46dP11PQvYd+Rk5QX5/HwKw3sO9LEiH7FQOCL6L8fXce6nYeZUdMvdE6NMfzsn2+xcfdhdh46weiBfULlE761nN+//A6PvLqT62eP5r3jzazb2cjLW9/lvue38uzmA9RWluD3CW/tP0pJfg4bdx+mT0EO//HLl/jO4xuZNaaSNmMoLchl35GTbNh9mBPNbfQtzGXN9kM89eY+/CJUlhaEnvdX/36ba+9bxajKEqr7FvL2gaOcaG6jqaWN4vwcjDGISGh/EQkrs7+2z96/ht889zbjqkoZVFbAw680cPGP/82f1zQweWgZWw8cY9kbu5kyrJx7nqqnpn8xxfmBeaYrtx7korv+xexxA9mw6zB3r9jCqMoSKorzQsd/5Z1D7G48QVVZAa+8c4jyojzufaaenzy1hT2HT5KX42NAn3zue34b1yxZyZiBfSgpyKEg18+GXYcpLcjl0LFm3j3aTGlhDouffZuCXD87Dh1n3c5GLr/3BeqGVzC0IvC5eeTVnfxz036mDQu871ra2vFZL7ut3eDzBc5FU2s78+59nh89sZlNe45w0YSBGANffeh1/rR6B6dWl9G3KBcR4URzGz9esYWJQ8rI8/tC57PxRAtX/uJFivL8XPmLF9n27jFOrS7jwNEm2oyhKK9r83Fvu+223bfeeutip22SqYu5iMhc4MeAH/i1MeZOt33r6upMts7wHXHT4wBsu/PSsPL2dsNtf1vPx88YwS2PvMHLWw8C8NKiCxhUVsDoW/5Oc1s7l02q4okNexlUWsA7B4+z4dtzGP/N5YjAX//zLMoKcynM8zPju0/FrMfkIWU8et3ZfPPRdQwsLeC5LQd48e13KS/K5dDxFgCGVhRyzcwR3LFsY9TjH/vi2Vx2z3NhZX6fUJTn58jJ1rDyHJ/Q2m54X21/fnVNHXXfWcHRpvB9AMYO6sM3LxvP1b9+GYDzxgwgz+/jiQ17Y76WoMe/dDaf+e1qdnehZTt73EBa2tr51+ZAS/yHV07m4LEmvrvszbD9PndODb989m0AfnVNHd9btpG3DxwLbR9fVcr0kRW8f3IVP3vmLZ56c1/Ua3zveAt7bC3Vs0f1Z9W2gzS1trvWb2BpPnsPN/GRuqE8uHpH2LZvXjaebz+2wfWx46pKqSor4GlbXcYO6sObe46E7ZeX46O5tZ0/fHYGv/73Vp5+cx+5fsEnwoenDaG8KI+fPlPv+BzTR1aw0nrPRjp39IDQeb1w/EAuGj+Q+1/czhs7G13rbFdWmEvjiRbX7fbju7nrI5P5yoOvJ/R8AKMHlrB571GmDOvL8aY2dr53gmvOGM7P/vlW1L6jKkuo33c0qnzBOTUstt4rAJOH9sUn8Na+oxw+Gf3+D+03pIyH//Ms/D5x3ceNiKwxxtQ5bstE8BcRP7AZuBBoAFYBVxljHN+xPSX4/3vLforzc5g6rDxlxwwG/63fuySsNVW/7yizf/QvagYU8/b+jmCy5BN1nD92YOhxkf668Cwuv/d5SvJzQgH1V9fU8dn7Y5+/AX3yeXnRBdTcvCzmfldMqeaRV3dGlX9l9mjuWrE55mOdTB7al017DnOyxT3QKeVlt18+kY/PHN6lx8YK/pla22c6UG+MeRtARB4A5gHuzZUe4OO/WQlEt9JTYfPeoxTl+RlaUcQjrzaEWiW+qJ/XsY9zsqUNgKI8fyj4n7DKYjHG0NIePwAfOt7sWB4M/J88awT3Pb8NCLSeV2yM3Upft7OR0oKcTgX/4C+HVBhXVcrG3Yddtxfm+qPO36wxA3hmU+yW5c2XjOUzZ9dw45/X8pdXGsK2PfGVcygrzGX+4pfYavuV4Ob8sZWcPqKC//lHx6+OuuHlrN5+CICrpg/jaFMrf3t9l+sxfvfp6Tywagfnj6nk/17ezpmn9OPIyVaeWL837FdHpD75ORyx/Sr7yVVTWLvjPX793Naw/e7/1HR++MQm1jY0Mn1kBfk5Pv695QCLLh7L9/4eqPcvPz6NptZ2vvTHVwHIz/E5/ro5d/QAZtb0464nN9Pc1s7804dyzugB1FaWcOFdz4b2m1lTwf/75HQ27j7M5r1H+MHyzRw42mSdk6F894pTMQZ++kw9pQU53PN0PSdb2rhowiCK8/1cOW0o3122kYnVZZQV5jJ1WDnP1R+grDCXkoIcNu85wgenVlNZWsC6nY385rmtUb9m7L+YFl08Fr9P+M7jG7l93gTeP3kwn/vdmtCv9gmDS7lhzhiGlhdy14otPL52N6dWl/HGzkaGVRTxqbNG8MeVO/jaRaMZP7iU3Y0neW7LAa46fajr/08yMhX8qwH7b9UGYEaG6hKmrd3w0OodfHjaEHL9yfWH1+87wt7DTZw1qn/o2A+u2sGVddHHnnN34E297c5LuevJLaHyyF968YJ/8MNkP37wwxZLW7uhpS1+QP1nnKA3oE8+EPhQlBYG3l6XTqri8bW7XZ83mFayO6OmH6/uOMTJlnZuv3wis8dVcsb3ngbgx/OnsPAPrwBw/exa7l7Rcb6+9f7x3Pa36DbEf80dGxY8g4ZVFMYM/rd9YAJf/8va0P2J1aXcPX8Kk297wvUxAAvOOQWA//2PyVw+ZXCo4dC3KJcR/YrJy/HxzA3n8fja3dz3/NZQIF9760XsO9zEtgPH8PuEYf2KOGVACUBY/f/8hTNZve0gv31xO7fPm8ADq3a4Bv/Pn3sK76sdwPtqA4s7fmjakNC2b8+bSHNrOwePNTOorIBX3znEFT97gatnDOPmS8ZRkOPjqTf3safxJBOrS5k2vIL3T6rik2ePBKDa1q/07y37WdvQyAVjK7n2zBEcbWpl+fo9AHxwajVzJgwCAum7XJ+Pwjw/xhj+8spOZo0ZQJsxVBTlhfpcrj1zOM2t7aF+LYA135hNcX4gjx80ZVg5U4aV85HTh9FufX4vnliFiCACX7qgFoBPnDUy6tw8+Lkzwu679b1V9y1kzoRB/Oyf9Xz/H5u4/fKJvH9SFX2L8jDGsOfwSarKCjHGcPGpVaHz8uDnzuBkSxvHmlrpV5IfOt69V0/l3quhpa2dQ8eaQ/0w9joOKS/i9BEVjvVJhUwFf6fkVVjkEZEFwAKAYcOGpb1CJ1vauPeZevqX5POtpetpPNHC5889xXHfcf/9DxZfMy30YXIz+0cdAR3g4VcauPmRNzh0vJmFs0a5Pq7N1qqNbPm3m9gjO5oSaOU7OdHSRkuMHHOiSgs6Oo2LrU6qMltHctBPrprCnsYTUTn0oKq+Bayx1iOcM2EglX0KQi3FmgHFof0WnFMTFvw/edZIpg4rZ0h5IVf+4kU+OLWaidVlnFM7wDH4Bx7T8WsF4LShfXltx3uBuhflhuVqf/epGZQWdHxsvnHpOMZXlYb6JZyU24LXnz9/Bnk5HV/Ml06q4uCxJlZvP8TD/3kmpQW5lBbkMqqyxPV4QXUjKqizgkN/W2ABuHLaEP60poGVN18Q+kJ2k5fjC3VoTxlWzu8/M4PTR1SE6hkM2kEiEhb07eUQ+CAX5PopyPWHGiFi+8jb3yNi9R84KcrLwXbqAMICqBOfT5g/PX3x4gvnnsKC99WEvqAg8BqqygpDtyPPTfBcOMn1+0KBv7tlKvg3APbfMkOAsGaLMWYxsBgCOf90V+gX/3qLe56up39J4N3mlt6AQKC8e8WWuME/UjCob3838FPfrb+l3VYeNaoCWB+jpRps+SeS6rE72dJO3R0rOvUYIKxDGAgLbEV5gTd8aUEujy48i/ue38p/zhrFs5v3c+mpVfxlTUPU8UoLckKdX7/5RB2/fWE7/YsDH/g/fHYG9zxdH2oJB54j+i08eWhfAJ6+4byw8l9fU0dV3wIKcv08/EoD9z4T6Kz7wnmncN/z27jhotGs3n6IL11Qyw+Xb+KFt96lKM/PpadWsfjZt/EJlFujT+69eipjBpUwqjIwYucXH5vK5//vFcdzFAysAMMqiqO2f2zmcM4c1T/sdcWy4JyaqLJ+JeFR8rwxlfzgyskJHS9S8JdqZwXfqRkaQ9ItRIQcf+c7XnuiTAX/VUCtiIwEdgLzgaszVBegI2jGGmGRrGALODhSIZi6iGQP/pFpnxUb9jJmUB/X52gOvo4u/AJo60Qe/TfX1jGjph8l+Tn87fVdfNFKLfkl+oPRpyCHyUP7cvf8KQChIY7BtBBAbWUJW/YdZWxVaSivak9VAEwbHsjxAqz46jk0t3YuyswePzB0O9hSA6jsU8D62+ZQlOe3DWsMbBMk9CVmPz2XTqoKO/bcieH37fqX5Ecd305EEg78gOOvxj4F4R/lgtzun8JTYg3bLLQ/dxZ/EfR2GZnkZYxpBa4DlgMbgYeMMeszUZeOOgX+DX00TSAYpnKyRb71oQgG/2Vv7HHcr832/ROZ9vnTmoaYnYTp+hLz+4Qln6ijtrKEJ75yDheMGxj6sF9mC4Q+2ztqv9X51q844re7xZ4OCbY2Dx0L/OISx8xgh1GVfUJj+eOlNZzk+MKDfHF+Tlhg/tpFoxlcVsCkoWUU5jn/ZHfzx8/OjCqLPH4yihzqM7BPeOogP6dzdU6Fz55Tw/Wza7lqRkfaxVjRP0UvXaVQxmb4GmOWGWNGG2NOMcbckal6RLJ/QE+5eRnzF7+UsmMHg/qxptit8rCWv8PY3ljBPzjaJ1WjYSDQQffM187j/LEDefKr54Za7kH2c2b/sgr+CrGnPeyC6ZnRA0uYMixw+6MzhnHxxEHcOGdMwvV79sZZXDGlmociOu9iyYnTmV83ooIXFl1AaUFuwhNsPmN1gp5xSr84e3bNgwtm8vGZwx0HIpQX57HmG7OZbvUBdGFIeNIKcv1cP3t02BdPVKNK9Ri94jKO3cG4/D5duc15okpntFuzAVut6B/rg9na1h7R4Ru9T6zg39lcfyLeP2kww/oVJbSvfSLKNy4dz9CKIs52ySEX5Pp57ItnM6isgH7FeQwoyWdmTT/HURmxFOb5uesjp3XqMaGWfwL7OrW0nXzjsvF847LxnapHZ8yo6Rc2YzhSv5L8jhZ2D4m254wOpO0+2sVx6ip9NPh3g4PHmykrzA21xp1a80Gt7Sa8w9dhn1gzVk+mIfhXuKRtnPhsOfNBZQX819yxMfefWF0Wun1mFzsau6IznXb5Vif2R2ekf9RZsoLvnHhps+4yuG9hWubFqOTpwm7doO47K1hw/+pQiz7ex7I9xlDPoFMGRI8aAbjn6fDp9k985ZzEK+oichhhLG717Wkic/6xiAibvjOX2+dNTHOtkveps0YAgVSaUrFo8I8QjF2pHqTwzKb9HS3/GAGy3Rja4uT8AUb2dw7+kdzy7XY5PmGqlXN3Mrx//JTP/NOH8rlza7q0/kgmdLbzNT/HH/MXW08xd2IV2+68NO54eKU0+HeRWxj4zXNb+a7DwmcAbe3BnL97EDEG2sNG+zjv5zRePFJRnj+Usoi338j+7i1F+6QcN3d+aBKLLh6XkY7GZPSSHypKpZwG/6CIpn5XY8Ltj20IW7nPLrh8gkhgqWEnUS1/h+jk90lC47j7FOSQ64u/3+2XT3Tt8H6yk2mj3tA6tsvmCUlKxaLBP0JolmIajt1mS/t8ZPGLjvucaG4L6/B1kuf3kchIzpL8nISC8bzTql2DYO1A9wllTpwmefVEvaOWSqWPBn9LaJREGoNXMOe/q/FE1NrpQdO/+1RYIH7hrXdDt/Os8d2t7e2uLXW7Pgmka4KCS00kkiaKpbd0+HbQpr/yJg3+aeK03n4w57/93eNdOmbfIlswTyBmRU75jyV4uO998FSWXndW5ypmE8wyJfLllEnp/JJXqjfQ4N+Nkp11G1wOwRjipoYgsY7aoODhfCJMGuI+8iee3pL2CdKcv/IqDf4JaG1rdx3BYxdrHaAcn9CWwHr5sRTnR0+bj2Xq8PhXHIsc2hq8X+MyjyCe4FDPnjLJSCnlTGf4JuCZTftdR/DYtcWIyDl+oSXJlr99TRe3Q3142hD+/sZujjW3UZPAXIBgP0Lwl0QwHfL4F9/XpdnCHWu6a5NaqZ5Mg78l2OHp1F5tbUtshcxYSyLn+HyhnH9X2YO/W3D1SXQrPpZg8A8+KPiQwjx/p1ezBHrNJK/JQwPLSlx75ojMVkSpDNHgHyGUBrG14p1iulNgjZWK8afgurP29WjcnssnEtqWSCDOtUb3pGrp3d6S86/sU6BrzihP05x/AhLpXIU4aZ8U5PxzEpiwJSKhQJ5IIA62/O0XL0lGL4n9SnmeBn8X9qGAiQb/WPulpOXvs7f8Y6R9giN3HFr+VRFr/dw2b4J1vMD9pFv+vSTto5TXafC3dMTS4GqPnQ/UJkZKP9fvS/hLxI097eP2PeITCeX8g4HYvhTEi4suYMVXA0s2nDKgOHRx7mDdko3dvW+Sl1LepME/glPsSkXaJz/Hl/SY8mCHr8G9w1eEUOdtMJC/efvFcY8d+woCSqlso8E/AU6DdLbsO8qih9eGxvY/+tpOfvvCNtdjvH3gGL97aXtS9bCnfWK3/OMvHR1peEVg2ebOXLglFp08pVTPpqN9LLFilVPL/73jLfxx5Q4+874aThlQwpcfeC19lbPkhDpnDeMGOS+4Jracf2fy7zfOHcOMmn5MH1mRdD2VUj2ftvwjOLVYe0ojNteW8//YzOGca10f1c6e84/X8re/rvwcPxeOH5iCWiqleoOkgr+IXCki60WkXUTqIrYtEpF6EdkkInNs5XOtsnoRuSmZ508Hx47eGNG/O9Mb9qGeIsL4waVR+/h9EnoNbsG/sjQw4udjM1J/UW3t71Wqd0g27bMO+CDwS3uhiIwH5gMTgMHAChEZbW2+F7gQaABWichSY8yGJOuRMk4pnmRH6aRKbsRFx+3VKivMpfFEC7b+Xte0T2lBrk5wUsrjkmr5G2M2GmM2OWyaBzxgjGkyxmwF6oHp1l+9MeZtY0wz8IC1b8YFA2mwI9UeWGMNz+/Olm5OVPDvqNgHp1Zb9bHP8O22qimlepl0hYdqYIftfoNV5lYeRUQWiMhqEVm9f//+NFUzmlPa5+ZH3oixfzprEy5yhm/wqW+6eCxDywOjdexr+GdizH1ZYWAZ6dO141ipHi1u2kdEVgCDHDbdYox51O1hDmUG5y8bx/BpjFkMLAaoq6vrthAbavl31xN2QnTap2Ni1sdmDudESxufPnskP1i+ySrv/uA/sLSAFV89J6ELzCulMidu8DfGzO7CcRuAobb7Q4Bd1m238owKjo0P5ve7O89/xZRqHnl1Z8x9cmyTvKDji0oQ8nJ8LJw1Kmz/TC21MKqyc9f9VUp1v3SlfZYC80UkX0RGArXASmAVUCsiI0Ukj0Cn8NI01aFLgkG/O2P/ypsvYM6E+MMsc3zOHb5uDXz72j7nj63kI3VDnXdUSnlOUqN9ROQK4B5gAPC4iLxmjJljjFkvIg8BG4BWYKExps16zHXAcsAPLDHGrE/qFaTAZ367mhUb9wIdrelYa/OnmohEXVP2+tm13L1iS1hZbkQPbjC2R34pBNlX9VzyidNTUFOlVLZIKvgbYx4BHnHZdgdwh0P5MmBZMs+basHADx159O5M+/gkupPkjJp+/KHPO+w70hQqi0zjfGl2LU2t7cyfPsz5uDraRynlQpd3iNAeMeSzO/h9EtU5m5/rj0rnRHb4lhbkcvvlE12PqytsKqXceLpt+OhrO3nn3eNhZaGWf8LRP/lviUDaJ7ysINcXdWGVRC7mYtdbrqqllOp+nm75f/mB1ygtCD8FHUM9EwvqL289yOC+hUnVw7Hln+OPWls/cpJXPE4Xc1FKKfB48Ac4fLLVsTzRlP8tj6zj2c3JTULzCVFJ//wcX1QncGeHbupVtZRSbjyd9omlMzn/V955L6nn8kl0y98pYxNM4yT6xaSxXynlRoO/i0TTPgD7bSNyusIn4dn9acPL6V+SH/UFEEzjjBmY2CQq7fBVSrnxfNrHTXdO8vJJR6CeMbKCBz93BhDd+veJ8IfPzGCMy4VcImnaRynlxrPBP94F2rtyAfeu8vuiR/tAdMtdgDNH9U/8uNryV0q58GzaJ15s785x/mJL+9jjdbKhW2O/UsqNd4N/nO1tPeACLpGjfTobzCMfr5RSQd4N/j0k7VOc53fdFhm6NZYrpVLFu8E/zvbuWtjtskmDXbd1NdhfF7G0s1JKRfJwh2/s7d2Z87ezD/p8a/8x122x3DBnDDfMGZPSeimlsotnW/7xVu1MfG0fpZTqfTwb/OPp7it5KaVUd/Js8O8paZ/gQp0JPZ12+CqlUsS7wT9OuO2ulv/X54xNeF+N/UqpVPFu8I8T27sj9l8/u5by4rz0P5FSSkXwbvCPs707r+FrF2t4p07aUkqlineDf7zRPmls+n/pglqrDml7CqWUiimp4C8iPxCRN0VkrYg8IiJ9bdsWiUi9iGwSkTm28rlWWb2I3JTM8ycjXtxNZ/APLrapsV8plSnJtvyfBCYaYyYBm4FFACIyHpgPTADmAj8TEb+I+IF7gYuB8cBV1r7dLpOjfYKTtey/PhL5rtGkj1IqVZIK/saYJ4wxwesgvgQMsW7PAx4wxjQZY7YC9cB066/eGPO2MaYZeMDat/vFCbZrth/qnnpEiJ3z7756KKWyWypz/p8C/m7drgZ22LY1WGVu5VFEZIGIrBaR1fv3J3eNXCeduVJXqgWDuOb8lVKZEndtHxFZAQxy2HSLMeZRa59bgFbg98GHOexvcP6ycQyBxpjFwGKAurq6lIfJTAbe4Mnp7BdQomv7KKVUPHGDvzFmdqztInItcBlwgelIYjcAQ227DQF2WbfdyrtVJhvdTi3/RL4INO2jlEqVZEf7zAX+C/iAMea4bdNSYL6I5IvISKAWWAmsAmpFZKSI5BHoFF6aTB26qjsv0xgpOF6/szUYWFqQ+soopTwp2SWdfwrkA09aAe0lY8znjTHrReQhYAOBdNBCY0wbgIhcBywH/MASY8z6JOvQJT0h3Z7o909tZQmLr6ljZP/i9FZIKeUZSQV/Y4zrVUOMMXcAdziULwOWJfO8qZDOhv+vrqnjs/evdt0eSvvYvoJy/YEfYSX50f8lImjgV0qllHdn+Kax7X/h+IFMGFzquj3UcWurwoyRFdw4Zwzf++CkqP310gJKqVTzbPBPd94ncm2gp752bui2OMzwFREWzhpFhcNCb3ptAaVUqnk2+Kc7nEbG69KC3NDt0FDPRIO6xn6lVIp5N/inu+Uf8QT2YZqdneSlLX+lVKp5N/inuTkdGbAl7HZiA/ZXfPVc61ipqpVSSgV4N/inOaBGHt9na/o75fyd5FkjgDK5FIVSKjt5N/in+fhRLX+Hxn68dE7wMe3tqaqVUkoFeDf4p7npH532sbf8E0v7lBYGOolnjR2QuooppRTJz/DttdKd9inM9YcXOMT7eHUoK8zlxUXn078kP3UVU0opPBz80604YqZu2GifThynqqwwNRVSSikbD6d90nv84ryI4G+7HbqMow7hVEpliHeDf4q7fO+5akrY/eL88LSPSHTOX0O/UipTvBv8Uxx5I/twh5YXhd332baXFgZ+FfQtil7KQSmluoNnc/6pbnVHTty6Yc4YagaUcPMjb0Rtnze5mhPN7Xx42hCUUioTPNzyT23490W0/Aty/Vw9Y1jovv2Xgc8nXD1jGHk5nj39SqkM82z0SXnLP8YQnosnOl0CWSmlMse7aZ8uRv9PnTWSJc9vjSp3m7i14dtzyPP7ohZ6U0qpTPJs8O9q27+kwPmUuTX8i6whn+2tukaDUqrn8G7ap4sNcbcgH2/JhgRXdFBKqW7hmeC/p/EkDYeOh+53NQnjFsTjxXafRn+lVA+SVPAXkdtFZK2IvCYiT4jIYKtcROQnIlJvbZ9qe8y1IrLF+rs22ReQqJnfe4qz/+eZ0P10j/OP2p7ap1NKqaQk2/L/gTFmkjHmNOAx4JtW+cVArfW3APg5gIhUAN8CZgDTgW+JSHmSdeiSrs7wdbsQS9zgr9FfKdWDJBX8jTGHbXeL6cimzAPuNwEvAX1FpAqYAzxpjDlojDkEPAnMTbLcYZoAABAbSURBVKYOXZXyln+ctn2iyzgrpVR3SHq0j4jcAVwDNAKzrOJqYIdttwarzK2823W5w9clhvsjZ3kppVQPFjf4i8gKwGmW0i3GmEeNMbcAt4jIIuA6Amkdp0hoYpQ7Pe8CAikjhg0b5rRLUrqe9umw/PpzKC3M4Y8vv8Op1WWpqZhSSnWDuMHfGDM7wWP9AXicQPBvAIbatg0Bdlnl50WU/9PleRcDiwHq6upSPkMqFWkfkcB6+1+9aAyNJ1qSP6BSSnWTZEf71NrufgB407q9FLjGGvUzE2g0xuwGlgMXiUi51dF7kVXWbRpPtPCLf72VkrSPPdMTLNfUvlKqN0g253+niIwB2oHtwOet8mXAJUA9cBz4JIAx5qCI3A6ssvb7tjHmYJJ16JRvPbqOv762iy9fUBt/57g6In1wHL9fo79SqhdIKvgbYz7kUm6AhS7blgBLknneZBw52QrAj5/a0qXH20fthLX8Q2Ua/JVSPZ9nZvgGpbLzIPzqXIF/fZ47o0qp3shzoaq1PXXh397GDx5WW/5Kqd7Ac8H/2c374+6zcNYprttEbK18W6AvsC7M8vU5Y5KroFJKdQMPL+ns7sY5YynKy+EHyzc5bveJ0GZM2MieHL+PbXde2k01VEqp5Hiu5Z8otxm7goQ6ejXDo5TqrTT4u8iJsVxDsKNX1+tRSvVWGvxduLb8pWMsv4Z+pVRvpcHfRZ+CXMdyoWN8v47sUUr1Vhr8XVwxxX2xUV8o7dNdtVFKqdTS4O/C7xOunhG9mqgI+Hwa/JVSvZsG/xjcYntotI9m/ZVSvZQG/xicWvaBoZ4a9JVSvZsG/xicWvaBGb6BcpPqa0EqpVQ30Rm+CRgzsA9bDxyjua0d6Ej7dHaZoF9+fBo1/YtTXDullOo8Df4xBLM7544ZQFG+n1ffeQ/omAPQ3smW/5wJTlfDVEqp7qdpnxjE9q89AXTpqVUAlBTod6dSqnfS6BWD0zIOIsKiS8axcNYoSl0mgimlVE+nLf8E2Dt5hUDap7w4L7OVUkqpJGjwT0Bk2kcppXo7Df4xOF20RYf4K6WygQb/BNiv3qWUUtkgJcFfRG4QESMi/a37IiI/EZF6EVkrIlNt+14rIlusv2tT8fzpEpzkJRG3lVKqt0t6tI+IDAUuBN6xFV8M1Fp/M4CfAzNEpAL4FlAHGGCNiCw1xhxKth7pEGztR472UUqp3i4VLf+7gK8TCOZB84D7TcBLQF8RqQLmAE8aYw5aAf9JYG4K6pAWwTlcoj2+Sqksk1TwF5EPADuNMa9HbKoGdtjuN1hlbuVOx14gIqtFZPX+/fuTqWaXGev7zCcdq/xow18plQ3ipn1EZAXgtC7BLcDNwEVOD3MoMzHKowuNWQwsBqirq8voCmqCBn2lVHaJG/yNMbOdykXkVGAk8LqVBx8CvCIi0wm06Ifadh8C7LLKz4so/2cX6t0twtI+Fv0OUEplgy6nfYwxbxhjKo0xI4wxIwgE9qnGmD3AUuAaa9TPTKDRGLMbWA5cJCLlIlJO4FfD8uRfRnqJiF64RSmVVdK1ts8y4BKgHjgOfBLAGHNQRG4HVln7fdsYczBNdUiZsJSP5n+UUlkgZcHfav0Hbxtgoct+S4AlqXreZPzfp2cwqrKEu57czIOrd7juJ0jHsM9uqptSSqWTp1f1PLu2PwCjB/Vx3B68UpdPZ/gqpbKMLu9A/MsxhnX46peAUioLaPCPITib16cdvkqpLKPBn44hnZGcWvn6JaCUygYa/OmYyRspuJSzMfZ1frqrVkoplT6eCP7xcvpum63rtHf6Qu1KKdXTeSL4//xfb8Xc7hbaQy1/W5k2/JVS2cATwX/5uj0xt7vn/AOhvq3d6FLOSqms4ongH497zt/aboyu6qmUyioa/ImV85eo7TraRymVDTT4xyChDl9t8Sulsosngn+8sTpuo4GCef52W9pHG/5KqWzgjeAfJ/q7bfeH0j7a4auUyi6eCP7xuH032NM+obK010YppdJPgz+dm+SlvwCUUtnAE8HfbShnvO0+XzDnry1+pVR28UTwj8d1khf2nH+wTCmlej8N/jGEp3007CulsocGf+Kv7RPW4avfAUqpLOCJ4B9/qKfbOP+Ox2vQV0plk6SCv4jcKiI7ReQ16+8S27ZFIlIvIptEZI6tfK5VVi8iNyXz/Inq6jh/n22SV5B+CSilskEqLuB+lzHmh/YCERkPzAcmAIOBFSIy2tp8L3Ah0ACsEpGlxpgNKahHp9iDeKcWdtPcv1IqC6Qi+DuZBzxgjGkCtopIPTDd2lZvjHkbQEQesPbt9uBv59rytw31DO6iLX+lVDZIRc7/OhFZKyJLRKTcKqsGdtj2abDK3MqjiMgCEVktIqv379+fVAXjru3jUm5f26elrR2A/BxPdJMopbJc3EgmIitEZJ3D3zzg58ApwGnAbuB/gw9zOJTbeEnH2GuMWWyMqTPG1A0YMCChF5NqPtvyDs2tweDvz0hdlFIqleKmfYwxsxM5kIj8CnjMutsADLVtHgLssm67lWdM/PX8TUfwz9WWv1Kq90t2tE+V7e4VwDrr9lJgvojki8hIoBZYCawCakVkpIjkEegUXppMHVLBdain9W+7MTS3actfKZU9ku3w/b6InEYgdbMN+ByAMWa9iDxEoCO3FVhojGkDEJHrgOWAH1hijFmfZB3icgru9vyTW86/sjQfgOq+RaxtaAQ056+Uyg5JBX9jzMdjbLsDuMOhfBmwLJnn7S6zxlTy62vqOG/MAB59fScABZr2UUplgXQN9exVYl3Ja/b4gUBHh2+eX9M+SqneT5uxwOxxA0O3PzR1iOM+TcHgr2kfpVQW8ETLP97yDjNq+rHtzktj7tOswV8plUU0kiUoOLNXg79SKht4ouXvpLOXY3xgwUyWrd1NcZ7m/JVSvZ9ng39njR1UythBpZmuhlJKpYQnchjxruGrlFJe44ngr5RSKpwGf6WU8iBPBH+noZ66LL9Sysu8EfwzXQGllOphPBH8nfQp0IFOSinv8mQE/PC0ISycNSrT1VBKqYzJ+pZ/W7uhft/RsLJPnDmCkf2LM1QjpZTKvKwP/n9Z0xBV5tOrsCulPC7rg/++Iyejyvw+Df5KKW/L+uDvNMxTY79SyuuyPvi3OV3CUdM+SimPy/rgH1yHP16ZUkp5iSeDf0ubBn+llLclHfxF5IsisklE1ovI923li0Sk3to2x1Y+1yqrF5Gbkn3+eJptgb6yTz7fuXwik4aUpftplVKqR0tqkpeIzALmAZOMMU0iUmmVjwfmAxOAwcAKERltPexe4EKgAVglIkuNMRuSqUcsTS0dwb8kP4ePzRyerqdSSqleI9kZvl8A7jTGNAEYY/ZZ5fOAB6zyrSJSD0y3ttUbY94GEJEHrH3TFvztLX9d40cppQKSTfuMBt4nIi+LyL9E5HSrvBrYYduvwSpzK08be87fxLuSu1JKeUTclr+IrAAGOWy6xXp8OTATOB14SERqcF4x2eD8ZeMYkUVkAbAAYNiwYfGq6aqpta3Lj1VKqWwVN/gbY2a7bRORLwAPm0CTeqWItAP9CbToh9p2HQLssm67lUc+72JgMUBdXV2Xm+xNOqxTKaWiJJv2+StwPoDVoZsHHACWAvNFJF9ERgK1wEpgFVArIiNFJI9Ap/DSJOsQU1jaJ51PpJRSvUiyHb5LgCUisg5oBq61fgWsF5GHCHTktgILjTFtACJyHbAc8ANLjDHrk6xDTGEdvhr9lVIKSDL4G2OagY+5bLsDuMOhfBmwLJnn7Qz7UE+llFIB2T/Dt62dU6sDk7qMJn6UUgrwQvBvbScvJ+tfplJKdUrWR8Xm1nbyreCvOX+llArI+uDf1NqmwV8ppSJkffAPtPz9ma6GUkr1KNkf/Ns056+UUpGyOiq2txta2kwo7aOUUiogq6NicIJXfm4w569Jf6WUgiwP/sF1fYI5fw39SikVkNXBvzkU/LP6ZSqlVKdldVTsX5LHljsu5qrpXV8SWimlslGyC7v1aCJCrl9Co30KcnXIp1JKQZYH/6DKPvncOGcM7580ONNVUUqpHsETwV9EWDhrVKaroZRSPUZW5/yVUko50+CvlFIepMFfKaU8SIO/Ukp5kAZ/pZTyIA3+SinlQRr8lVLKgzT4K6WUB0lvWOZYRPYD25M4RH/gQIqq09vpuQin5yOcno8O2XAuhhtjBjht6BXBP1kistoYU5fpevQEei7C6fkIp+ejQ7afC037KKWUB2nwV0opD/JK8F+c6Qr0IHouwun5CKfno0NWnwtP5PyVUkqF80rLXymllI0Gf6WU8qCsDv4iMldENolIvYjclOn6dAcRGSoiz4jIRhFZLyJftsorRORJEdli/VtulYuI/MQ6R2tFZGpmX0HqiYhfRF4Vkces+yNF5GXrXDwoInlWeb51v97aPiKT9U4HEekrIn8WkTet98gZXn1viMhXrM/IOhH5o4gUeOm9kbXBX0T8wL3AxcB44CoRGZ/ZWnWLVuBrxphxwExgofW6bwKeMsbUAk9Z9yFwfmqtvwXAz7u/ymn3ZWCj7f7/AHdZ5+IQ8Gmr/NPAIWPMKOAua79s82PgH8aYscBkAufFc+8NEakGvgTUGWMmAn5gPl56bxhjsvIPOANYbru/CFiU6Xpl4Dw8ClwIbAKqrLIqYJN1+5fAVbb9Q/tlwx8whEBAOx94DBACszZzIt8nwHLgDOt2jrWfZPo1pPBclAJbI1+TF98bQDWwA6iw/q8fA+Z46b2RtS1/Ov5zgxqsMs+wfppOAV4GBhpjdgNY/1Zau2X7ebob+DrQbt3vB7xnjGm17ttfb+hcWNsbrf2zRQ2wH7jPSoP9WkSK8eB7wxizE/gh8A6wm8D/9Ro89N7I5uAvDmWeGdcqIiXAX4DrjTGHY+3qUJYV50lELgP2GWPW2IsddjUJbMsGOcBU4OfGmCnAMTpSPE6y9nxY/RrzgJHAYKCYQJorUta+N7I5+DcAQ233hwC7MlSXbiUiuQQC/++NMQ9bxXtFpMraXgXss8qz+TydBXxARLYBDxBI/dwN9BWRHGsf++sNnQtrexlwsDsrnGYNQIMx5mXr/p8JfBl48b0xG9hqjNlvjGkBHgbOxEPvjWwO/quAWqv3Po9AZ87SDNcp7UREgN8AG40xP7JtWgpca92+lkBfQLD8Gmtkx0ygMZgC6O2MMYuMMUOMMSMI/P8/bYz5KPAM8GFrt8hzETxHH7b279WtOztjzB5gh4iMsYouADbgwfcGgXTPTBEpsj4zwXPhnfdGpjsd0vkHXAJsBt4Cbsl0fbrpNZ9N4OfoWuA16+8SAvnJp4At1r8V1v5CYFTUW8AbBEY/ZPx1pOG8nAc8Zt2uAVYC9cCfgHyrvMC6X29tr8l0vdNwHk4DVlvvj78C5V59bwC3AW8C64DfAfleem/o8g5KKeVB2Zz2UUop5UKDv1JKeZAGf6WU8iAN/kop5UEa/JVSyoM0+CullAdp8FdKKQ/6/whCcb68GUwuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train(env, agent))\n",
    "    agent.epsilon *= 0.99\n",
    "    \n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to Coursera I: Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_rewards1 = rewards.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarized state spaces\n",
    "\n",
    "Use agent to train efficiently on CartPole-v0.\n",
    "This environment has a continuous set of possible states, so you will have to group them into bins somehow.\n",
    "\n",
    "The simplest way is to use `round(x,n_digits)` (or numpy round) to round real number to a given amount of digits.\n",
    "\n",
    "The tricky part is to get the n_digits right for each state to train effectively.\n",
    "\n",
    "Note that you don't need to convert state to integers, but to __tuples__ of any kind of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"first state:%s\" % (env.reset()))\n",
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play a few games\n",
    "\n",
    "We need to estimate observation distributions. To do so, we'll play a few games and record all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(1000):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s, r, done, _ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done: break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    plt.hist(all_states[:, obs_i], bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.core import ObservationWrapper\n",
    "class Binarizer(ObservationWrapper):\n",
    "    \n",
    "    def observation(self, state):    \n",
    "        \n",
    "        #state = <round state to some amount digits.>\n",
    "        #hint: you can do that with round(x,n_digits)\n",
    "        #you will need to pick a different n_digits for each dimension\n",
    "        state[0] = np.round(state[0],0)\n",
    "        state[1] = np.round(state[1],1)\n",
    "        state[2] = np.round(state[2],2)\n",
    "        state[3] = np.round(state[3],1)\n",
    "        return tuple(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Binarizer(gym.make(\"CartPole-v0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "for _ in range(1000):\n",
    "    all_states.append(env.reset())\n",
    "    done = False\n",
    "    while not done:\n",
    "        s, r, done, _ = env.step(env.action_space.sample())\n",
    "        all_states.append(s)\n",
    "        if done: break\n",
    "            \n",
    "all_states = np.array(all_states)\n",
    "\n",
    "for obs_i in range(env.observation_space.shape[0]):\n",
    "    \n",
    "    plt.hist(all_states[:,obs_i],bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn binarized policy\n",
    "\n",
    "Now let's train a policy that uses binarized state space.\n",
    "\n",
    "__Tips:__ \n",
    "* If your binarization is too coarse, your agent may fail to find optimal policy. In that case, change binarization. \n",
    "* If your binarization is too fine-grained, your agent will take much longer than 1000 steps to converge. You can either increase number of iterations and decrease epsilon decay or change binarization.\n",
    "* Having 10^3 ~ 10^4 distinct states is recommended (`len(QLearningAgent._qvalues)`), but not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
    "                       get_legal_actions=lambda s: range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for i in range(10000):\n",
    "    rewards.append(play_and_train(env,agent))   \n",
    "    \n",
    "    #OPTIONAL YOUR CODE: adjust epsilon\n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit to Coursera II: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_rewards2 = rewards.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submit import submit_qlearning\n",
    "submit_qlearning(submit_rewards1, submit_rewards2, 'olonok@gmail.com','WvG28B6L5BQE1EwR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
